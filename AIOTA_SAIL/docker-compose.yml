version: '3.8'

services:
  # =========================================
  # 1. QUEUE & MEMORY (Redis)
  # =========================================
  redis:
    image: redis:alpine
    container_name: aiota_redis
    restart: always
    # Optional: Persist Redis to disk if you want active sessions to survive reboot
    volumes:
      - ./redis_data:/data

  # =========================================
  # 2. MQTT BROKER (Mosquitto)
  # =========================================
  mosquitto:
    image: eclipse-mosquitto:2
    container_name: aiota_mqtt
    restart: always
    ports:
      - "1883:1883"  # Exposed port for ESP32s
    volumes:
      - ./mosquitto/config:/mosquitto/config

  # =========================================
  # 3. AI BRAIN (Llama Chat Server)
  # =========================================
  llama_chat:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: aiota_brain
    restart: always
    # TUNING FOR 2 PARALLEL SLOTS:
    # -np 2: Open 2 slots
    # -cb: Enable continuous batching (Required for parallel)
    # -t 8: Use all cores (The server manages splitting them dynamically)
    command: -m /models/Llama-3.2-3B-Instruct-Q4_K_M.gguf --host 0.0.0.0 --port 8080 -c 8192 -np 2 -cb -t 8
    volumes:
      - ./models:/models
    deploy:
      resources:
        limits:
          cpus: '8.0' # Allow full CPU usage
          memory: 12G

  # =========================================
  # 4. AI MEMORY (Embedding Server)
  # =========================================
  llama_embed:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: aiota_embed
    restart: always
    # Embeddings are fast, 4 threads is plenty
    command: -m /models/nomic-embed-text-v1.5.Q4_K_M.gguf --host 0.0.0.0 --port 8081 --embedding -c 2048 -cb -t 4
    volumes:
      - ./models:/models
    deploy:
      resources:
        limits:
          cpus: '4.0'
          memory: 4G

  # =========================================
  # 5. CONTROLLER (Your Python Logic)
  # =========================================
  ai_controller:
    build: .
    container_name: aiota_controller
    restart: always
    # Wait for others to start before launching script
    depends_on:
      - mosquitto
      - redis
      - llama_chat
      - llama_embed
    environment:
      - PYTHONUNBUFFERED=1
    volumes:
      # Persist the logs so you can analyze student data later
      - ./logs:/app/data
      # Mount ChromaDB so you don't lose RAG data
      - ./chroma_db:/app/chroma_db